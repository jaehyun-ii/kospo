import asyncio
import json
from typing import Dict, List
from langchain_openai import OpenAIEmbeddings   
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from dotenv import load_dotenv
load_dotenv()

def load_sensor_data(json_file_path: str) -> Dict:
    """JSON íŒŒì¼ì—ì„œ ì„¼ì„œ ë°ì´í„° ë¡œë“œ"""
    with open(json_file_path, 'r', encoding='utf-8') as file:
        return json.load(file)
    
def create_documents(sensor_data: Dict) -> List[Document]:
    """ì„¼ì„œ ë°ì´í„°ë¡œë¶€í„° Document ê°ì²´ ìƒì„±"""
    documents = []
    
    for sensor_id, sensor_info in sensor_data.items():
        # ì„¼ì„œ IDë¥¼ ë” ê°•ì¡°í•˜ê³  ë‹¤ì–‘í•œ í‘œí˜„ìœ¼ë¡œ í¬í•¨
        content = f"""
        ì„¼ì„œ ID: {sensor_id}
        ì„¼ì„œëª…: {sensor_id}
        ì„¤ëª…: {sensor_info['description']}
        ë‹¨ìœ„: {sensor_info['unit']}
        
        ì´ ì„¼ì„œëŠ” {sensor_id}ë¡œ ë¶ˆë¦¬ë©°, {sensor_info['description']}ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
        ì¸¡ì • ë‹¨ìœ„ëŠ” {sensor_info['unit']}ì…ë‹ˆë‹¤.
        """
        
        document = Document(
            page_content=content.strip(),
            metadata={
                "sensor_id": sensor_id,
                "description": sensor_info["description"],
                "unit": sensor_info["unit"]
            }
        )
        documents.append(document)
    
    return documents


async def test_faiss_rag():
    """FAISS RAG ê°„ë‹¨ í…ŒìŠ¤íŠ¸ - ë°ì´í„° ë¡œë“œ, ë²¡í„° ìŠ¤í† ì–´ ìƒì„±, ìœ ì‚¬ë„ ê²€ìƒ‰"""
    print("ğŸš€ FAISS RAG í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. ì„¼ì„œ ë°ì´í„° ë¡œë“œ
    print("1. ì„¼ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    sensor_data = load_sensor_data("src/data/sensor_data.json")
    print(f"   ë¡œë“œëœ ì„¼ì„œ ìˆ˜: {len(sensor_data)}")
    
    # 2. Document ìƒì„±
    print("2. Document ìƒì„± ì¤‘...")
    documents = create_documents(sensor_data)
    print(f"   ìƒì„±ëœ Document ìˆ˜: {len(documents)}")
    
    # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print("3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
    
    # 4. FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    print("4. FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    vector_store = FAISS.from_documents(documents=documents, embedding=embeddings)
    print("   ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ!")
    
    # 5. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    test_queries = [
        "ì••ì¶•ë¹„ (Compressor Pressure Ratio)",
        "11G_CPR ì´ê±°ë­ì„?",
        "11G_A_96KP05_F1 ì´ê±°ë­ì„?"
    ]
    
    print("\n5. ìœ ì‚¬ë„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("-" * 30)
    
    for query in test_queries:
        print(f"\nì§ˆë¬¸: '{query}'")
        
        # ì„¼ì„œ ID ì¶”ì¶œ (11G_ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„)
        import re
        sensor_id_match = re.search(r'11G_[A-Z0-9_]+', query)
        if sensor_id_match:
            sensor_id = sensor_id_match.group()
            print(f"  ì¶”ì¶œëœ ì„¼ì„œ ID: {sensor_id}")
            
            # ì •í™•í•œ ì„¼ì„œ IDë¡œ ì§ì ‘ ê²€ìƒ‰
            if sensor_id in sensor_data:
                exact_sensor = sensor_data[sensor_id]
                print(f"  âœ… ì •í™•í•œ ì„¼ì„œ ì •ë³´: {sensor_id} - {exact_sensor['description']} ({exact_sensor['unit']})")
            else:
                print(f"  âŒ ì„¼ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {sensor_id}")
        
        # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
        results = vector_store.similarity_search(query, k=5)
        print("  ë²¡í„° ê²€ìƒ‰ ê²°ê³¼:")
        for i, doc in enumerate(results, 1):
            print(f"    {i}. {doc.metadata['sensor_id']} - {doc.metadata['description']}")
    
    print("\nâœ… FAISS RAG í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    await test_faiss_rag()


if __name__ == "__main__":
    asyncio.run(main())
